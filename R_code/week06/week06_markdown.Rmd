---
title: 'Ordination'
output: html_document
---

We're going to run through a bunch of ordination techniques today, generally increasing in complexity.  We'll start off with our arthropod dataset, then work with a plant community dataset in order to incorporate environmental data.


```{r}
commDat=read.csv("U:/LOCKED/arthropod_data/commComp_2000.csv",na.strings=c("","NA"))
comm=commDat[,-c(1:6)]#creating a dataset without all the species ID info, for the sake of convenience later
rownames(comm)=commDat[,1]
library(vegan)
```

As mentioned in the lecture, we are going to start with a DCA to estimate gradient length

```{r}
comm.dca=decorana(t(comm))
comm.dca
```

The gradient length is given in the "Axis lengths" row for each DCA axis.  The first axis has a length of 3.88standard deviations.  The rule of thumb is <3SD = linear, 3-4 = either, >4 = unimodal.  Ours is a bit of a tweener, so we'll use both linear and non-linear methods.

We can plot our DCA results, with both community and species, or each separately.

```{r}
plot(comm.dca)
plot(comm.dca,display="sites")
plot(comm.dca,display="species")
```

It's kind of hard to visualize here, so let's make some plots on our own.

```{r}
#the raw outputs from the DCA can be accessed with the summary() function
dcaSites=scores(comm.dca)
dcaSpp=scores(comm.dca,display="species")
plot(dcaSites[,1],dcaSites[,2],col=rep(c("Red","Orange","Blue","Green"),each=10),xlab="DCA1",ylab="DCA2")
```

Looks like Narrowleaf (green) and BC (blue) are similar (not surprising, the latter is a back-cross between the F1 and narrowleaf), and F1 (orange) is kind of between BC and Fremont, though there appears to be a lot of variation within F1.  The gradient is most apparent when both axes are taken into consideration.

Let's see if we get a similar result with a linear ordination model, non-metric multidimensional scaling.

The first step is to generate a distance matrix.  Recall from the Anderson et al. paper last week that there are many distance metrics that we can use to represent beta diversity (i.e. differences in composition) across communities.  For now we are going to stick with the standard Bray-Curtis distance, which does a good job of accounting for zero data.

```{r}
library(ecodist)#this libary has a function for calculating Bray-Curtis distance
bcDist=bcdist(t(comm))
comm.nms=nmds(bcDist,mindim=1,maxdim=2)#NMDS utilizes a random seed to initiate calculation of orthogonal axes.  Because of this, the default is to run the analysis many times, then select the run with the lowest "stress" (disagreement between the raw and ordinated data).
comm.nms.min=nmds.min(comm.nms)#this function finds the run with the minimum stress
plot(comm.nms.min[,1],comm.nms.min[,2],col=rep(c("Red","Orange","Blue","Green"),each=10),xlab="NMS1",ylab="NMS2")
```

This tells a similar story to that of the DCA, though there appear to be two groups (Fremont + F1; Narrowleaf + BC) rather than a gradient.  Notice also that the first axes does not discriminate among tree types, only the second does, suggesting that the primary differentiation among arthropod communities is not driven by tree type.

Another way to visualize these patterns is through cluster analysis.  This is also based on the Bray-Curtis distance matrix generated above.

```{r}
plot(hclust(bcDist,method="average"),labels=colnames(comm))
```

With a few exceptions, the largest split in the cluster analysis appears to be between the two groups delineated in the NMS plot.  We can test the hypotheses that (1) communities differ among tree types, and (2) that they fall into two groups, rather than four, using PermANOVA (adonis in vegan)

```{r}
comm.perm=adonis(t(comm)~rep(c("Fre","F1","BC","Nar"),each=10),method="bray")
comm.perm#this prints out a typical ANOVA table
```

We see that the F statistic of the observed data is much greater than expected from the distribution of F statistics generated by permuting the distance matrix (this is how a "Perm"ANOVA works).

What if we (1) compared Nar and BC, (2) Fre and F1?

```{r}
comm.perm.NarBC=adonis(t(comm[,21:40])~rep(c("BC","Nar"),each=10),method="bray")
comm.perm.NarBC#no difference
comm.perm.FreF1=adonis(t(comm[,1:20])~rep(c("Fre","F1"),each=10),method="bray")
comm.perm.FreF1#significant difference
```

Based on these results, it appears that there are three groups: (1) Fremont, (2) F1, (3) Back-cross+Narrowleaf.


OK, now we're going to bring in a different dataset with environmental variables and functional trait data so that we can do constrained ordinations and a principal components analysis.

```{r}
grassComm=read.csv(file="U:/LOCKED/grassland_data/community_comp.csv",row.names=1)#this is a grassland community composition dataset with percent cover, rather than number of individuals
env=read.csv(file="U:/LOCKED/grassland_data/environmental.csv",row.names=1)#these are environmental variables that correspond with each community
traits=read.csv(file="U:/LOCKED/grassland_data/traits_cwm.csv",row.names=1)#these are community mean trait values
```

As before, let's do a DCA to assess gradient length

```{r}
grass.dca=decorana(grassComm)
grass.dca
```

Again, we have a tweener (length of first DCA axis = 3.64), so we can do either linear or non-linear constrained ordinations.

First, however, we want to see how well our environmental variables (elevation and soil bulk density) correlate with the unconstrained ordination.  If we put in a variable that doesn't correlate well, the constrained ordination will do a poor job of representing variation in community composition along environmental gradients.

Let's start with the unconstrained, non-linear model (DCA) since we already have it.

```{r}
cor(scores(grass.dca),env)
```

We can see that elevation correlates strongly with the first DCA axis, while bulk density correlates only moderately with both the first and second axes.  Let's plot environmental vectors on our DCA to see how communities are arrayed along environmental axes.

```{r}
dca.biplot=envfit(scores(grass.dca),env)
plot(grass.dca,display="sites")
plot(dca.biplot)
```

Let's try a CCA (constrained, non-linear) with just elevation, since it had the strongest correlation with the DCA, and both elevation and bulk density.

```{r}
grass.cca.elev=cca(grassComm~elev,data=env)
grass.cca.elevBD=cca(grassComm~elev+BD,data=env)
grass.cca.elevBD#compare the "Eigenvalues for constrained axes" to those of the first two DCA axes.  These eigenvalues are proportional to the variance explained in the community dataset by each axis.  Notice that less variance is explained by the CCA, because this method maximized the variance explained by the environmental data, not maximizing the variance explained in the community dataset alone
plot(grass.cca.elevBD,display=c("wa","cn"))
```

Compare this to the biplot of the DCA.  There are some shifts in where different communities are positioned relative to one another.  We can do the exact same analysis with the linear constrained methods RDA, just use the rda() function instead of cca().

OK, last ordination method!  We're going to do a principal components analysis (PCA) on the community-mean trait values of each community and see how they correspond with the environment.  PCA is useful for dimensionality reduction of normally distributed variables of similar "types" (e.g. trait variables, environmental variables), but typically not for community data given that they are often based on counts or have many zeros.

First we have to standardize our variables by converting them to Z-scores

```{r}
zScore=function(x){
  return((x-mean(x))/sd(x))
}
zTraits=apply(traits,2,zScore)
library(psych)#we're going to use the principal() function in the psych library because it allows us to do useful rotations; there are quite a few PCA functions in R, but you need to be careful to understand the subtle differences among them
pca.traits=principal(zTraits,nfactors=6,rotate="varimax")#we're selecting a relatively large number of components (6), we can cut this down in a minute; we're also doing a varimax rotation (see below)
pca.traits
```

First let's look at the eigenvalues.  Rule of thumb is to exclude any components with eigenvalues less than one, which essentially means that they explain less variance than the raw variables.  We'll use a scree plot:

```{r}
plot(pca.traits$values)
```

Usually we like to see an obvious "break" or drop in the variance explained, but this one is pretty smooth.  We'll stick with the first four principal components, given our cutoff of eigenvalue >1.

```{r}
pca.traits=principal(zTraits,nfactors=4,rotate="varimax")#this time constraining to 4 components
pca.traits
```

The matrix of "loadings" is essentially the correlation coefficient between the raw trait variable and the new principal component.  The rule of thumb is that loadings of 0.7 or greater are considered high (~half or more of the variance in the original variable is explained by the PC (0.7^2)).  Based on this rule of thumb, our PCs appear to represent:
1. +Seed size, +height, +specific leaf area, -relative growth rate, -root diameter; so big plants that grow fast
2. +Root density, +specific root length, -proportion of roots that are fine (as opposed to coarse); so plants with big, dense roots
3. -Leaf dry matter content, +leaf area; big, juicy leaves (forbs)
4. +Leaf C:N ration, -root mass fraction; legumes

Now we have four dimensions that does a pretty good job of explaining the original 12 traits that clearly had some redundancies in information content.

The varimax rotation we did is an orthogonal rotation of the original principal components that maximizes the variances in loadings sequentially on each component, i.e. you tend to get either high or low loadings, which makes it easier to distinguish which variables correspond with each axis.  I highly recommend using this rotation in most circumstances.

OK, let's see how these variables relate to our environmental factors.

```{r}
cor(pca.traits$scores,env)
```

Looks like plant size (PC1) declines strongly with elevation, while root size and density (PC2) and forbs (PC3) increase moderately.  Forbs (PC3) and plant size (PC1) also decline with bulk density.

Finally, we can visualize this in the same was as for the DCA

```{r}
pca.biplot=envfit(pca.traits$scores,env)
plot(pca.traits$scores)
plot(pca.biplot)
```

